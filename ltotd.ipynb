{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Splunk Message Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Name Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter file names for each required parameter; if not in same folder, provide path\n",
    "\n",
    "# .csv containing all s-tag messages\n",
    "s_tag_messages = 'S_TagFile.csv' \n",
    "# Splunk query: index=\"rtr-prod\" raw_ocs_message tmov | regex _raw=\"[A-Z]*[S][A-Z]*[01]\\d{3}\"\n",
    "\n",
    "# .csv containing all NEW TSCH messages for the O, R, and B lines\n",
    "tsch_messages = 'TSCH_Messages.csv' \n",
    "# Splunk query: index = \"rtr-prod\" raw_ocs_message TSCH NEW (O OR R OR B)\n",
    "\n",
    "# .csv containing all trips between the hours of 11pm and 2am the next day (same revenue day)\n",
    "night_trips = 'LateNightTrips.csv'\n",
    "# Splunk query: \n",
    "# index=\"rtr-prod\" raw_ocs_message TMOV (R OR B OR O)\n",
    "#| eval event_hour=strftime(_time, \"%H\")\n",
    "#| where (event_hour >= \"23\" OR event_hour < \"02\")\n",
    "\n",
    "# Enter a name for the output .csv (if a .csv export is required)\n",
    "output_file_name = 'YourFileName.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# Required file to calculate closest station\n",
    "locations = pd.read_csv('PathToLocationFile')\n",
    "\n",
    "# Function to assign the correct revenue day to each entry\n",
    "def assign_revenue_day(df):\n",
    "    # Convert the 'timestamp' column to a datetime object\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    # Define the time boundaries for a revenue day\n",
    "    start_time = pd.to_datetime('05:00:00').time()\n",
    "    end_time = pd.to_datetime('02:00:00').time()\n",
    "\n",
    "    # Assign revenue days based on the timestamp\n",
    "    df['revenue_day'] = df['timestamp'].apply(lambda x: x.date() if x.time() >= start_time else (x.date() - pd.DateOffset(days=1)))\n",
    "\n",
    "    # Convert the 'revenue_day' column to the desired string format\n",
    "    df['revenue_day'] = df['revenue_day'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to find the closest location\n",
    "def find_closest_location(lat, lon, locations):\n",
    "    distances = np.sqrt((locations['latitude'] - lat) ** 2 + (locations['longitude'] - lon) ** 2)\n",
    "    closest_index = distances.idxmin()\n",
    "    return locations.loc[closest_index, 'loc_name']\n",
    "\n",
    "# Function that finds the first & last instances of each train_UID per revenue day, along with location when tagged/untagged\n",
    "def first_last_instance(df):\n",
    "    # Convert the 'timestamp' column to a datetime object\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-d %H:%M:%S.%f')\n",
    "\n",
    "    # Sort the DataFrame by 'revenue_day', 'train_UID', and 'timestamp'\n",
    "    df = df.sort_values(by=['revenue_day', 'train_UID', 'timestamp'])\n",
    "\n",
    "    # Initialize a list to store the processed data\n",
    "    processed_data = []\n",
    "\n",
    "    # Iterate through unique revenue days\n",
    "    for revenue_day, day_group in df.groupby('revenue_day'):\n",
    "        # Group by 'trip_UID' within the revenue day\n",
    "        trip_groups = day_group.groupby('train_UID')\n",
    "        \n",
    "        for train_UID, trip_group in trip_groups:\n",
    "            # Find the first and last instances of each train_UID within the revenue day\n",
    "            first_instance = trip_group.iloc[0]  # First row\n",
    "            last_instance = trip_group.iloc[-1]  # Last row\n",
    "            \n",
    "            # Extract the relevant data\n",
    "            time_tagged = first_instance['timestamp']\n",
    "            time_untagged = last_instance['timestamp']\n",
    "            trip_UID = first_instance['trip_UID']\n",
    "            train_id = train_UID\n",
    "            line = last_instance['transit_line']\n",
    "            lat = first_instance['lat']\n",
    "            lon = first_instance['lon']\n",
    "\n",
    "            # Find the closest location\n",
    "            loc_name = find_closest_location(lat, lon, locations)\n",
    "\n",
    "            # Check if time_tagged is within 5 minutes or less of time_untagged\n",
    "            if (time_untagged - time_tagged) >= timedelta(minutes=5):\n",
    "                # Append the data to the processed_data list\n",
    "                processed_data.append([revenue_day, line, trip_UID, train_id, time_tagged, time_untagged, loc_name, lat, lon])\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    result_df = pd.DataFrame(processed_data, columns=['revenue_day', 'line', 'trip_UID', 'train_id', 'time_tagged', 'time_untagged', 'loc_name', 'lat', 'lon'])\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def determine_recorded_departure_time(recorded_df, tsch_df, locations):\n",
    "    result_df = pd.DataFrame(columns=['trip_UID', 'train_UID', 'transit_line', 'lat', 'lon', 'train_id', 'revenue_day', 'recorded_departure', 'location','recorded_departure_trimmed'])\n",
    "\n",
    "    # Iterate over unique trip_UIDs in recorded movement dataframe\n",
    "    for trip_UID in recorded_df['trip_UID'].unique():\n",
    "        trip_events = recorded_df[recorded_df['trip_UID'] == trip_UID].sort_values(by='timestamp')\n",
    "\n",
    "        # Iterate over each event for the current trip_UID\n",
    "        for index, event in trip_events.iterrows():\n",
    "            current_time = event['timestamp']\n",
    "\n",
    "            # Check if there is another event within 20 seconds\n",
    "            next_event_candidates = trip_events[(trip_events['timestamp'] > current_time) & \n",
    "                                                 (trip_events['timestamp'] <= current_time + pd.Timedelta(seconds=20))]\n",
    "\n",
    "            if not next_event_candidates.empty:\n",
    "                next_event = next_event_candidates.iloc[0, :]\n",
    "\n",
    "                # Calculate the closest location to the current event using lat and lon\n",
    "                closest_location = find_closest_location(event['lat'], event['lon'], locations)\n",
    "\n",
    "                # Check if the closest location contains \"departure\" in the 'loc_name'\n",
    "                if 'departing' in closest_location.lower():\n",
    "                    # Save the recorded departure time and location\n",
    "                    recorded_departure_time = current_time\n",
    "                    location = closest_location\n",
    "\n",
    "                    # Convert recorded_departure_time to datetime and format as HH:MM\n",
    "                    recorded_departure_trimmed = pd.to_datetime(recorded_departure_time).strftime('%H:%M')\n",
    "\n",
    "                    temp_df = pd.DataFrame({\n",
    "                        'trip_UID': [trip_UID],\n",
    "                        'train_UID': [event['train_UID']],\n",
    "                        'transit_line': [event['transit_line']],\n",
    "                        'lat': [event['lat']],\n",
    "                        'lon': [event['lon']],\n",
    "                        'train_id': [event['train_id']],\n",
    "                        'revenue_day': [event['revenue_day']],\n",
    "                        'recorded_departure': [recorded_departure_time],\n",
    "                        'recorded_departure_trimmed': [recorded_departure_trimmed],\n",
    "                        #'scheduled_departure': [None],  # Placeholder for scheduled departure time\n",
    "                        'location': [location]\n",
    "                    })\n",
    "                    result_df = pd.concat([result_df, temp_df], ignore_index=True)\n",
    "                    break  # Exit the loop once a valid departure time is found\n",
    "                \n",
    "    # Merge with scheduled departure time from tsch dataframe\n",
    "    result_df = pd.merge(result_df, tsch_df[['trip_UID', 'scheduled_departure']], on='trip_UID', how='inner')\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Function to combine the results of functions which calculate first and last trip, as well as recorded departure time\n",
    "def process_dataframes(first_last_trip, departure_time):\n",
    "    result = pd.merge(departure_time, first_last_trip[['trip_UID', 'time_tagged', 'loc_name']], on='trip_UID', how='inner')\n",
    "    result['time_tagged_trimmed'] = pd.to_datetime(result['time_tagged']).dt.strftime('%H:%M')\n",
    "    result['tagged_before'] = result['time_tagged'] < result['recorded_departure']\n",
    "    result['time_tagged'] = pd.to_datetime(result['time_tagged'])\n",
    "    result['recorded_departure'] = pd.to_datetime(result['recorded_departure'])\n",
    "    result['time_difference'] = result['time_tagged'] - result['recorded_departure']\n",
    "    result['time_diff'] = result['recorded_departure'] - result['time_tagged']\n",
    "    result['time_difference_trimmed'] = result['time_diff'].apply(lambda x: '{:02}:{:02}'.format(int(x.total_seconds() // 60), int(x.total_seconds() % 60)))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-Tag (LTOTD) Message Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tags = pd.read_csv(s_tag_messages)\n",
    "s_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tags['message'] = s_tags['_raw'].str.extract(r'raw_ocs_message (.*)')\n",
    "\n",
    "# Split data based on comma divisions\n",
    "split_data = s_tags['message'].str.split(',', expand=True)\n",
    "\n",
    "# CHANGE COLUMNS AS NAMING CONVENTIONS/MESSAGES ARE UPDATED/ALTERED\n",
    "columns = ['sequence', 'group_type', 'timestamp', 'transit_line', 'train_UID', 'lat', 'lon', 'train_tag',\n",
    "           'direction_route', 'trip_UID', 'train_id', 'express', 'last_lat', 'last_lon']\n",
    "\n",
    "# Assign the correct column names\n",
    "split_data.columns = columns\n",
    "\n",
    "# Convert columns to appropriate data types, handling empty entries\n",
    "split_data['sequence'] = split_data['sequence'].astype(float)  # Converting to float to handle potential NaN values\n",
    "split_data['lat'] = split_data['lat'].replace('', float('nan')).astype(float)\n",
    "split_data['lon'] = split_data['lon'].replace('', float('nan')).astype(float)\n",
    "split_data['train_tag'] = split_data['train_tag'].replace('', float('nan')).astype(float)\n",
    "split_data['direction_route'] = split_data['direction_route'].replace('', float('nan')).astype(float)\n",
    "#split_data['train_id'] = pd.to_numeric(split_data['train_id'], errors='coerce')\n",
    "split_data['timestamp'] = s_tags['_time']\n",
    "split_data['timestamp'] = pd.to_datetime(split_data['timestamp'], format='%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "s_tag_raw = split_data\n",
    "\n",
    "# To check that dtypes were updated correctly\n",
    "s_tag_raw.dtypes\n",
    "\n",
    "# Assign revenue day\n",
    "assign_revenue_day(s_tag_raw)\n",
    "\n",
    "# Check the final dataframe\n",
    "s_tag_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSCH Message Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsch = pd.read_csv(tsch_messages)\n",
    "tsch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsch['message'] = tsch['_raw'].str.extract(r'raw_ocs_message (.*)')\n",
    "t_split_data = tsch['message'].str.split(',', expand=True)\n",
    "columns = ['sequence', 'group_type', 'timestamp', 'transit_line', 'message_type','trip_UID', 'add_type', 'trip_type', 'scheduled_departure', 'scheduled_arrival',\n",
    "          'route', 'origin', 'destination', 'prev_trip_id', 'next_trip_id']\n",
    "t_split_data.columns = columns\n",
    "\n",
    "# Check if split worked\n",
    "t_split_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late Night Trips (11pm~2am) Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_nt = pd.read_csv(night_trips)\n",
    "late_nt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_nt['message'] = late_nt['_raw'].str.extract(r'raw_ocs_message (.*)')\n",
    "nt_split = late_nt['message'].str.split(',', expand=True)\n",
    "columns = ['sequence', 'group_type', 'timestamp', 'transit_line', 'train_UID', 'lat', 'lon', 'train_tag',\n",
    "           'direction_route', 'trip_UID', 'train_id', 'express', 'last_lat', 'last_lon']\n",
    "nt_split.columns = columns\n",
    "\n",
    "# Convert columns to appropriate data types, handling empty entries\n",
    "nt_split['sequence'] = nt_split['sequence'].astype(float)  # Converting to float to handle potential NaN values\n",
    "nt_split['lat'] = nt_split['lat'].replace('', float('nan')).astype(float)\n",
    "nt_split['lon'] = nt_split['lon'].replace('', float('nan')).astype(float)\n",
    "nt_split['train_tag'] = nt_split['train_tag'].replace('', float('nan')).astype(float)\n",
    "nt_split['direction_route'] = nt_split['direction_route'].replace('', float('nan')).astype(float)\n",
    "nt_split['timestamp'] = late_nt['_time']\n",
    "nt_split['timestamp'] = pd.to_datetime(nt_split['timestamp'], format='%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "nt_raw = nt_split\n",
    "\n",
    "assign_revenue_day(nt_raw)\n",
    "\n",
    "nt_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process All DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_last_trip = first_last_instance(s_tag_raw)\n",
    "recorded_departure = determine_recorded_departure_time(nt_raw, t_split_data, locations)\n",
    "result = process_dataframes(first_last_trip, recorded_departure)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(output_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_counts = result.groupby(['revenue_day', 'transit_line'])['trip_UID'].unique().reset_index()\n",
    "\n",
    "unique_train_counts = result.groupby(['revenue_day', 'transit_line'])['trip_UID'].nunique().reset_index()\n",
    "\n",
    "colors = ['blue', 'orange', 'red']\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.barplot(data = unique_train_counts, x='revenue_day', y='trip_UID', hue='transit_line', palette=colors)\n",
    "\n",
    "plt.title('Number of Unique Trip_UIDs per Line per Revenue Day')\n",
    "plt.xlabel('Revenue Day')\n",
    "plt.ylabel('Number of Unique Trip IDs')\n",
    "plt.legend(title='Line', title_fontsize='15')\n",
    "\n",
    "plt.xticks(rotation=80)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
